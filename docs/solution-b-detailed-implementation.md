# æ–¹æ¡ˆBè¯¦ç»†å®æ–½æ–¹æ¡ˆ - ä¿ç•™SQLBot RAG + æ›¿æ¢Claude LLM

> è‹æ”¿æºä¸€æœ¬è´¦æ™ºèƒ½é—®æ•° - è¯¦ç»†å®æ–½æŒ‡å—
> æ–¹æ¡ˆï¼šä¿ç•™SQLBotçš„RAGå±‚ï¼Œæ›¿æ¢LLMä¸ºClaude
> è®¾è®¡æ—¶é—´ï¼š2026-02-08

---

## ğŸ“‹ æ–¹æ¡ˆBæ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 SQLBot å‰ç«¯                     â”‚
â”‚              (React - æ— éœ€ä¿®æ”¹ï¼‰                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚ HTTP/WebSocket
                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 SQLBot åç«¯                     â”‚
â”‚              (FastAPI - æ”¹åŠ¨æœ€å°ï¼‰              â”‚
â”‚                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚         RAG å¢å¼ºå±‚ï¼ˆä¿ç•™ï¼‰               â”‚   â”‚
â”‚  â”œâ”€â†’ Schema (æ•°æ®åº“è¡¨ç»“æ„ï¼‰                 â”‚   â”‚
â”‚  â”œâ”€â†’ Terminology (æœ¯è¯­åº“)                   â”‚   â”‚
â”‚  â”œâ”€â†’ Data Training (SQLç¤ºä¾‹)              â”‚   â”‚
â”‚  â”œâ”€â†’ Custom Prompt (ä¸šåŠ¡è§„åˆ™)              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚         Prompt æ„å»ºå±‚ï¼ˆä¿ç•™ï¼‰             â”‚   â”‚
â”‚  â”œâ”€â†’ sql_sys_question()                    â”‚   â”‚
â”‚  â”œâ”€â†’ æ³¨å…¥ Schema                           â”‚   â”‚
â”‚  â”œâ”€â†’ æ³¨å…¥ Terminology                      â”‚   â”‚
â”‚  â”œâ”€â†’ æ³¨å…¥ Data Training                    â”‚   â”‚
â”‚  â”œâ”€â†’ æ³¨å…¥ Custom Prompt                    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚         LLM è°ƒç”¨å±‚ï¼ˆæ”¹è¿™é‡Œï¼ï¼‰           â”‚   â”‚
â”‚  â”œâ”€â†’ LLMFactory.create_llm()              â”‚   â”‚
â”‚  â”œâ”€â†’ åŸæ¥ï¼šOpenAI/é€šä¹‰åƒé—®/VLLM           â”‚   â”‚
â”‚  â””â”€â†’ æ–°å¢ï¼šClaude (ChatAnthropic)        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚         æ•°æ®è®¿é—®å±‚ï¼ˆä¿ç•™ï¼‰               â”‚   â”‚
â”‚  â”œâ”€â†’ SQL æ‰§è¡Œ                              â”‚   â”‚
â”‚  â”œâ”€â†’ ç»“æœæ ¼å¼åŒ–                            â”‚   â”‚
â”‚  â””â”€â†’ å›¾è¡¨ç”Ÿæˆ                              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PostgreSQL æ•°æ®åº“                 â”‚
â”‚  â”œâ”€â†’ ä¸šåŠ¡æ•°æ®è¡¨ï¼ˆè‹æ”¿æºä¸€æœ¬è´¦ï¼‰                â”‚
â”‚  â”œâ”€â†’ SQLBot ç³»ç»Ÿè¡¨                         â”‚
â”‚  â”œâ”€â†’ terminology (æœ¯è¯­åº“)                    â”‚
â”‚  â”œâ”€â†’ data_training (SQLç¤ºä¾‹)                â”‚
â”‚  â””â”€â†’ ai_model_detail (LLMé…ç½®)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ æ ¸å¿ƒæ”¹åŠ¨ç‚¹

### åªéœ€ä¿®æ”¹3ä¸ªåœ°æ–¹ï¼

#### æ”¹åŠ¨ 1ï¼šapps/ai_model/llm.py

**æ–°å¢ Claude LLM ç±»**

```python
# apps/ai_model/llm.py

from langchain_anthropic import ChatAnthropic

class ClaudeLLM(BaseLLM):
    """Claude LLM å®ç°"""
    
    def _init_llm(self) -> BaseChatModel:
        """åˆå§‹åŒ– Claude LLM å®ä¾‹"""
        return ChatAnthropic(
            model=self.config.model_name,  # claude-3-5-sonnet-20241022
            api_key=self.config.api_key,
            temperature=self.config.additional_params.get('temperature', 0),
            streaming=True,
            **self.config.additional_params
        )
```

**ä¿®æ”¹ LLMFactory æ³¨å†Œ**

```python
# apps/ai_model/llm.py

class LLMFactory:
    """å¤§è¯­è¨€æ¨¡å‹å·¥å‚ç±»"""

    _llm_types: Dict[str, Type[BaseLLM]] = {
        "openai": OpenAILLM,        # ä¿ç•™
        "tongyi": OpenAILLM,        # ä¿ç•™
        "vllm": OpenAIvLLM,        # ä¿ç•™
        "azure": OpenAIAzureLLM,    # ä¿ç•™
        "claude": ClaudeLLM,        # æ–°å¢ï¼
    }

    @classmethod
    @lru_cache(maxsize=32)
    def create_llm(cls, config: LLMConfig) -> BaseLLM:
        llm_class = cls._llm_types.get(config.model_type)
        if not llm_class:
            raise ValueError(f"Unsupported LLM type: {config.model_type}")
        return llm_class(config)

    @classmethod
    def register_llm(cls, model_type: str, llm_class: Type[BaseLLM]):
        """æ³¨å†Œæ–°æ¨¡å‹ç±»å‹"""
        cls._llm_types[model_type] = llm_class
```

---

#### æ”¹åŠ¨ 2ï¼šapps/ai_model/model_factory.py

**ä¿®æ”¹ get_default_config() æ–¹æ³•**

```python
# apps/ai_model/model_factory.py

async def get_default_config() -> LLMConfig:
    """è·å–é»˜è®¤ LLM é…ç½®"""
    
    with Session(engine) as session:
        # æŸ¥è¯¢ default_model=True çš„é…ç½®
        db_model = session.exec(
            select(AiModelDetail).where(AiModelDetail.default_model == True)
        ).first()
        
        if not db_model:
            raise Exception("The system default model has not been set")

        # è§£æ additional_params
        additional_params = {}
        if db_model.config:
            try:
                config_raw = json.loads(db_model.config)
                additional_params = {
                    item["key"]: prepare_model_arg(item.get('val'))
                    for item in config_raw
                    if "key" in item and "val" in item
                }
            except Exception:
                pass
        
        # è§£å¯† API Key å’Œ Endpointï¼ˆå¦‚æœåŠ å¯†ï¼‰
        if not db_model.api_domain.startswith("http"):
            db_model.api_domain = await sqlbot_decrypt(db_model.api_domain)
            if db_model.api_key:
                db_model.api_key = await sqlbot_decrypt(db_model.api_key)
        
        # æ„é€  LLMConfigï¼ˆæ”¯æŒ Claudeï¼‰
        # protocol: 1=OpenAIå…¼å®¹, 2=VLLM
        # å¯¹äº Claudeï¼Œä½¿ç”¨ protocol=1 (OpenAIå…¼å®¹)
        return LLMConfig(
            model_id=db_model.id,
            model_type="claude" if "claude" in db_model.base_model.lower() 
                          else "openai" if db_model.protocol == 1 
                          else "vllm",
            model_name=db_model.base_model,
            api_key=db_model.api_key,
            api_base_url=db_model.api_domain,
            additional_params=additional_params,
        )
```

---

#### æ”¹åŠ¨ 3ï¼šæ•°æ®åº“é…ç½®ï¼ˆæ·»åŠ  Claude æ¨¡å‹ï¼‰

**SQL æ’å…¥è¯­å¥**

```sql
-- æ·»åŠ  Claude 3.5 Sonnet æ¨¡å‹é…ç½®
INSERT INTO ai_model_detail (
    name,                    -- æ¨¡å‹åç§°
    base_model,              -- åŸºç¡€æ¨¡å‹ï¼ˆClaude æ¨¡å‹åï¼‰
    protocol,                -- åè®®ç±»å‹ï¼ˆ1=OpenAIå…¼å®¹ï¼‰
    api_domain,             -- API åœ°å€
    api_key,                -- API Keyï¼ˆåŠ å¯†å­˜å‚¨ï¼‰
    type_name,               -- ç±»å‹åç§°ï¼ˆç”¨äº LLMFactoryï¼‰
    default_model,           -- æ˜¯å¦ä¸ºé»˜è®¤æ¨¡å‹
    temperature,            -- æ¸©åº¦å‚æ•°
    config,                 -- é¢å¤–é…ç½®ï¼ˆJSONï¼‰
    oid,                    -- æ‰€å±ç»„ç»‡
    created_at,
    updated_at
) VALUES (
    'Claude 3.5 Sonnet',                           -- name
    'claude-3-5-sonnet-20241022',                 -- base_model
    1,                                                -- protocol (OpenAIå…¼å®¹)
    'https://api.anthropic.com',                    -- api_domain
    'your-claude-api-key-here',                   -- api_key
    'claude',                                        -- type_name
    true,                                            -- default_model
    0.0,                                             -- temperature
    '[]',                                            -- config (JSONå­—ç¬¦ä¸²)
    1,                                                -- oid (ç»„ç»‡ID)
    NOW(),                                           -- created_at
    NOW()                                            -- updated_at
);
```

**SQL æ›´æ–°ä¸ºé»˜è®¤æ¨¡å‹**

```sql
-- å°†æ‰€æœ‰æ¨¡å‹è®¾ä¸ºéé»˜è®¤
UPDATE ai_model_detail SET default_model = false;

-- å°† Claude è®¾ä¸ºé»˜è®¤
UPDATE ai_model_detail 
SET default_model = true 
WHERE base_model = 'claude-3-5-sonnet-20241022';
```

---

## ğŸ”§ è¯¦ç»†å®æ–½æ­¥éª¤

### æ­¥éª¤ 1ï¼šå®‰è£…ä¾èµ–ï¼ˆ10åˆ†é’Ÿï¼‰

```bash
cd /Users/guchuan/codespace/SQLBot/backend

# å®‰è£… LangChain Anthropic é›†æˆ
pip install langchain-anthropic

# éªŒè¯å®‰è£…
python -c "from langchain_anthropic import ChatAnthropic; print('OK')"
```

---

### æ­¥éª¤ 2ï¼šåˆ›å»º Claude LLM ç±»ï¼ˆ30åˆ†é’Ÿï¼‰

**æ–‡ä»¶**ï¼š`apps/ai_model/llm.py`

**ä»£ç **ï¼š

```python
# apps/ai_model/llm.py

# åœ¨æ–‡ä»¶é¡¶éƒ¨å¯¼å…¥
from langchain_anthropic import ChatAnthropic

# åœ¨ BaseLLM ç±»åæ·»åŠ  Claude LLM ç±»
class ClaudeLLM(BaseLLM):
    """
    Claude LLM å®ç°
    åŸºäº Anthropic Claude 3.5 Sonnet
    """
    
    def _init_llm(self) -> BaseChatModel:
        """
        åˆå§‹åŒ– Claude LLM å®ä¾‹
        
        Returns:
            ChatAnthropic: LangChain Claude å®ä¾‹
        """
        return ChatAnthropic(
            # æ¨¡å‹åç§°ï¼ˆå¿…å¡«ï¼‰
            model=self.config.model_name,
            # Claude API Keyï¼ˆå¿…å¡«ï¼‰
            api_key=self.config.api_key or 'Empty',
            # API Base URLï¼ˆé»˜è®¤ï¼šhttps://api.anthropic.comï¼‰
            base_url=self.config.api_base_url,
            # æ¸©åº¦å‚æ•°ï¼ˆ0-1ï¼Œé»˜è®¤0ï¼‰
            temperature=self.config.additional_params.get('temperature', 0),
            # æœ€å¤§ Token æ•°ï¼ˆé»˜è®¤4096ï¼‰
            max_tokens=self.config.additional_params.get('max_tokens', 4096),
            # å¯ç”¨æµå¼å“åº”
            streaming=True,
            # å…¶ä»–é¢å¤–å‚æ•°
            **{k: v for k, v in self.config.additional_params.items() 
               if k not in ['temperature', 'max_tokens']}
        )
```

---

### æ­¥éª¤ 3ï¼šæ³¨å†Œ Claude LLMï¼ˆ20åˆ†é’Ÿï¼‰

**æ–‡ä»¶**ï¼š`apps/ai_model/llm.py`

**ä»£ç **ï¼šä¿®æ”¹ `LLMFactory` ç±»

```python
# apps/ai_model/llm.py

class LLMFactory:
    """å¤§è¯­è¨€æ¨¡å‹å·¥å‚ç±»"""

    # LLM ç±»å‹æ³¨å†Œè¡¨
    _llm_types: Dict[str, Type[BaseLLM]] = {
        "openai": OpenAILLM,        # OpenAI GPT
        "tongyi": OpenAILLM,        # é˜¿é‡Œäº‘é€šä¹‰åƒé—®
        "vllm": OpenAIvLLM,        # VLLM (æœ¬åœ°éƒ¨ç½²ï¼‰
        "azure": OpenAIAzureLLM,    # Azure OpenAI
        "claude": ClaudeLLM,        # Claude Anthropicï¼ˆæ–°å¢ï¼ï¼‰
    }

    @classmethod
    @lru_cache(maxsize=32)
    def create_llm(cls, config: LLMConfig) -> BaseLLM:
        """
        åˆ›å»º LLM å®ä¾‹ï¼ˆå·¥å‚æ–¹æ³•ï¼‰
        
        Args:
            config (LLMConfig): LLM é…ç½®å¯¹è±¡
            
        Returns:
            BaseLLM: LLM å®ä¾‹
            
        Raises:
            ValueError: ä¸æ”¯æŒçš„ LLM ç±»å‹
        """
        llm_class = cls._llm_types.get(config.model_type)
        if not llm_class:
            raise ValueError(f"Unsupported LLM type: {config.model_type}")
        return llm_class(config)

    @classmethod
    def register_llm(cls, model_type: str, llm_class: Type[BaseLLM]):
        """
        æ³¨å†Œæ–°æ¨¡å‹ç±»å‹ï¼ˆç”¨äºæ‰©å±•ï¼‰
        
        Args:
            model_type (str): æ¨¡å‹ç±»å‹æ ‡è¯†
            llm_class (Type[BaseLLM]): LLM ç±»
        """
        cls._llm_types[model_type] = llm_class
```

---

### æ­¥éª¤ 4ï¼šä¿®æ”¹ get_default_config()ï¼ˆ30åˆ†é’Ÿï¼‰

**æ–‡ä»¶**ï¼š`apps/ai_model/model_factory.py`

**ä»£ç **ï¼šä¿®æ”¹ `get_default_config()` å‡½æ•°

```python
# apps/ai_model/model_factory.py

async def get_default_config() -> LLMConfig:
    """
    è·å–é»˜è®¤ LLM é…ç½®
    ä»æ•°æ®åº“ä¸­è¯»å– default_model=True çš„é…ç½®
    
    Returns:
        LLMConfig: LLM é…ç½®å¯¹è±¡
        
    Raises:
        Exception: æœªè®¾ç½®é»˜è®¤æ¨¡å‹
    """
    with Session(engine) as session:
        # æŸ¥è¯¢é»˜è®¤æ¨¡å‹
        db_model = session.exec(
            select(AiModelDetail).where(AiModelDetail.default_model == True)
        ).first()
        
        if not db_model:
            raise Exception("The system default model has not been set")

        # è§£æé…ç½®ï¼ˆconfig å­—æ®µæ˜¯ JSON å­—ç¬¦ä¸²ï¼‰
        additional_params = {}
        if db_model.config:
            try:
                config_raw = json.loads(db_model.config)
                # è½¬æ¢ä¸ºå­—å…¸
                additional_params = {
                    item["key"]: prepare_model_arg(item.get('val'))
                    for item in config_raw
                    if "key" in item and "val" in item
                }
            except Exception as e:
                print(f"Warning: Failed to parse config: {e}")
                pass
        
        # è§£å¯† API Key å’Œ Endpoint
        # æ³¨æ„ï¼šå¦‚æœä½ çš„ç³»ç»Ÿæœ‰åŠ å¯†ï¼Œéœ€è¦è§£å¯†
        if not db_model.api_domain.startswith("http"):
            # å‡è®¾æœ‰ sqlbot_decrypt å‡½æ•°
            db_model.api_domain = await sqlbot_decrypt(db_model.api_domain)
            if db_model.api_key:
                db_model.api_key = await sqlbot_decrypt(db_model.api_key)
        
        # ç¡®å®š model_type
        # protocol: 1=OpenAIå…¼å®¹, 2=VLLM
        # Claude ä½¿ç”¨ OpenAI å…¼å®¹åè®®ï¼Œæ‰€ä»¥ model_type="claude"
        if "claude" in db_model.base_model.lower():
            model_type = "claude"
        elif db_model.protocol == 1:
            model_type = "openai"
        elif db_model.protocol == 2:
            model_type = "vllm"
        else:
            model_type = "openai"
        
        # æ„é€  LLMConfig
        return LLMConfig(
            model_id=db_model.id,
            model_type=model_type,
            model_name=db_model.base_model,
            api_key=db_model.api_key,
            api_base_url=db_model.api_domain,
            additional_params=additional_params,
        )
```

---

### æ­¥éª¤ 5ï¼šæ·»åŠ  Claude æ¨¡å‹åˆ°æ•°æ®åº“ï¼ˆ10åˆ†é’Ÿï¼‰

**æ–¹å¼ 1ï¼šé€šè¿‡ SQL æ’å…¥**

```sql
-- æ·»åŠ  Claude 3.5 Sonnet
INSERT INTO ai_model_detail (
    name,
    base_model,
    protocol,
    api_domain,
    api_key,
    type_name,
    default_model,
    temperature,
    config,
    oid,
    created_at,
    updated_at
) VALUES (
    'Claude 3.5 Sonnet',
    'claude-3-5-sonnet-20241022',
    1,
    'https://api.anthropic.com',
    'sk-ant-api03-your-api-key-here',
    'claude',
    true,
    0.0,
    '[]',
    1,
    NOW(),
    NOW()
);

-- è®¾ç½®ä¸ºé»˜è®¤æ¨¡å‹
UPDATE ai_model_detail 
SET default_model = true 
WHERE base_model = 'claude-3-5-sonnet-20241022';
```

**æ–¹å¼ 2ï¼šé€šè¿‡å‰ç«¯æ·»åŠ **

1. å¯åŠ¨ SQLBot
2. è®¿é—®ï¼šhttp://localhost:8000
3. è¿›å…¥ï¼šç³»ç»Ÿè®¾ç½® â†’ AI æ¨¡å‹ç®¡ç†
4. ç‚¹å‡»"æ·»åŠ æ¨¡å‹"
5. å¡«å†™é…ç½®ï¼š
   - åç§°ï¼š`Claude 3.5 Sonnet`
   - åŸºç¡€æ¨¡å‹ï¼š`claude-3-5-sonnet-20241022`
   - åè®®ç±»å‹ï¼š`OpenAI`
   - API åœ°å€ï¼š`https://api.anthropic.com`
   - API Keyï¼šä½ çš„ Claude API Key
   - ç±»å‹åç§°ï¼š`claude`
   - æ¸©åº¦ï¼š`0`
6. ç‚¹å‡»"è®¾ä¸ºé»˜è®¤"

---

### æ­¥éª¤ 6ï¼šéªŒè¯é…ç½®ï¼ˆ10åˆ†é’Ÿï¼‰

```bash
# å¯åŠ¨ SQLBot åç«¯
cd /Users/guchuan/codespace/SQLBot/backend
python main.py

# è®¿é—®å‰ç«¯æµ‹è¯•
# http://localhost:8000

# æµ‹è¯•æŸ¥è¯¢
# è¾“å…¥ï¼š"ç³»ç»Ÿæ•°é‡"
# é¢„æœŸï¼šåº”è¯¥ä½¿ç”¨ Claude ç”Ÿæˆ SQL
```

**éªŒè¯ç‚¹**ï¼š
- [ ] Claude æ¨¡å‹å·²æ·»åŠ åˆ°æ•°æ®åº“
- [ ] Claude å·²è®¾ç½®ä¸ºé»˜è®¤æ¨¡å‹
- [ ] SQLBot åç«¯å¯åŠ¨æˆåŠŸ
- [ ] å‰ç«¯å¯ä»¥æ­£å¸¸è®¿é—®
- [ ] æµ‹è¯•æŸ¥è¯¢ï¼ŒSQL æ­£ç¡®ç”Ÿæˆ
- [ ] æŸ¥çœ‹æ—¥å¿—ï¼Œç¡®è®¤ä½¿ç”¨çš„æ˜¯ Claude

---

### æ­¥éª¤ 7ï¼šæµ‹è¯•å’Œè°ƒä¼˜ï¼ˆ1-2å°æ—¶ï¼‰

#### æµ‹è¯•åœºæ™¯ 1ï¼šç®€å•æŸ¥è¯¢

```sql
-- æµ‹è¯• SQL
-- è¾“å…¥ï¼š"ç³»ç»Ÿæ•°é‡"
-- é¢„æœŸ SQLï¼š
SELECT COUNT(*) FROM t_sys;

-- éªŒè¯ç‚¹ï¼š
- [ ] SQL è¯­æ³•æ­£ç¡®
- [ ] ç»“æœå‡†ç¡®
- [ ] å“åº”æ—¶é—´å¯æ¥å—ï¼ˆ<3ç§’ï¼‰
```

#### æµ‹è¯•åœºæ™¯ 2ï¼šå¤æ‚æŸ¥è¯¢

```sql
-- æµ‹è¯• SQL
-- è¾“å…¥ï¼š"2025å¹´å—äº¬å¸‚çœå‚ç³»ç»Ÿæ•°é‡"
-- é¢„æœŸ SQLï¼š
SELECT COUNT(*) 
FROM t_sys 
WHERE year = 2025 
  AND city = 'å—äº¬å¸‚' 
  AND type = 'çœå‚';

-- éªŒè¯ç‚¹ï¼š
- [ ] SQL è¯­æ³•æ­£ç¡®
- [ ] å¤šä¸ªæ¡ä»¶æ­£ç¡®ç»„åˆ
- [ ] æœ¯è¯­"çœå‚"æ­£ç¡®åŒ¹é…
- [ ] ç»“æœå‡†ç¡®
```

#### æµ‹è¯•åœºæ™¯ 3ï¼šæœ¯è¯­åŒ¹é…

```sql
-- æµ‹è¯•æœ¯è¯­
-- è¾“å…¥ï¼š"å‚ç®¡ç³»ç»Ÿæ•°é‡"
-- é¢„æœŸï¼šé€šè¿‡æœ¯è¯­åº“åŒ¹é…ï¼Œç”Ÿæˆ WHERE type = 'çœå‚'

-- éªŒè¯ç‚¹ï¼š
- [ ] æœ¯è¯­åº“æ­£ç¡®åŒ¹é…
- [ ] SQL æ­£ç¡®æ³¨å…¥æœ¯è¯­æ¡ä»¶
```

#### æµ‹è¯•åœºæ™¯ 4ï¼šSQL ç¤ºä¾‹

```sql
-- æµ‹è¯• SQL ç¤ºä¾‹ï¼ˆFew-shotï¼‰
-- è¾“å…¥ï¼š"ç³»ç»Ÿæ€»æ•°é‡"
-- é¢„æœŸï¼šå‚è€ƒ SQL ç¤ºä¾‹ç”Ÿæˆ

-- éªŒè¯ç‚¹ï¼š
- [ ] SQL ç¤ºä¾‹æ­£ç¡®å¼•ç”¨
- [ ] ç”Ÿæˆçš„ SQL ä¸ç¤ºä¾‹é£æ ¼ä¸€è‡´
```

---

## ğŸ” æ—¥å¿—å’Œè°ƒè¯•

### æŸ¥çœ‹ LLM è°ƒç”¨æ—¥å¿—

```python
# åœ¨ apps/chat/task/llm.py ä¸­æ·»åŠ æ—¥å¿—

class LLMService:
    def __init__(self, session, current_user, chat_question, ...):
        # ...
        
        # æ·»åŠ æ—¥å¿—ï¼šæ˜¾ç¤ºä½¿ç”¨çš„æ¨¡å‹
        SQLBotLogUtil.info(f"Using LLM: {self.config.model_name} (type: {self.config.model_type})")
```

### æŸ¥çœ‹ç”Ÿæˆçš„ Prompt

```python
# åœ¨ apps/chat/task/llm.py ä¸­æ·»åŠ æ—¥å¿—

class LLMService:
    def generate_sql(self, question: str) -> str:
        # æ„å»ºç³»ç»Ÿ Prompt
        sys_prompt = self.chat_question.sql_sys_question(self.ds.type)
        
        # æ·»åŠ æ—¥å¿—ï¼šæ˜¾ç¤º Prompt ç‰‡æ®µ
        SQLBotLogUtil.info(f"Schema length: {len(self.ds.schema)}")
        SQLBotLogUtil.info(f"Terminologies count: {len(self.chat_question.terminologies)}")
        SQLBotLogUtil.info(f"Data training count: {len(self.chat_question.data_training)}")
```

---

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

### Claude vs é€šä¹‰åƒé—®

| æŒ‡æ ‡ | é€šä¹‰åƒé—® | Claude 3.5 Sonnet |
|------|---------|------------------|
| **å‡†ç¡®æ€§** | ä¸­ç­‰ | é«˜ |
| **å“åº”æ—¶é—´** | å¿«ï¼ˆ~2ç§’ï¼‰ | ä¸­ç­‰ï¼ˆ~3ç§’ï¼‰ |
| **æˆæœ¬** | ä½ï¼ˆÂ¥0.008/1K tokensï¼‰ | ä¸­ç­‰ï¼ˆ$3.00/1M tokensï¼‰ |
| **ç†è§£èƒ½åŠ›** | ä¸­ç­‰ | é«˜ |
| **ä¸­æ–‡æ”¯æŒ** | ä¼˜ç§€ | ä¼˜ç§€ |

### æˆæœ¬ä¼°ç®—ï¼ˆå‡è®¾ï¼‰

| æ“ä½œ | é€šä¹‰åƒé—® | Claude 3.5 Sonnet | å·®å¼‚ |
|------|---------|------------------|------|
| **1K tokens** | Â¥0.008 | $0.003 (çº¦Â¥0.022) | +175% |
| **æ—¥å‡æŸ¥è¯¢100æ¬¡** | Â¥32/å¤© | Â¥88/å¤© | +175% |
| **æœˆå‡æŸ¥è¯¢3000æ¬¡** | Â¥960/æœˆ | Â¥2640/æœˆ | +175% |

**å»ºè®®**ï¼š
- å¼€å‘/æµ‹è¯•é˜¶æ®µï¼šä½¿ç”¨é€šä¹‰åƒé—®ï¼ˆæˆæœ¬ä½ï¼‰
- ç”Ÿäº§ç¯å¢ƒï¼šä½¿ç”¨ Claude 3.5 Sonnetï¼ˆå‡†ç¡®æ€§é«˜ï¼‰

---

## ğŸ¨ é…ç½®ç¤ºä¾‹

### Claude 3.5 Sonnet é…ç½®

```json
{
  "model_id": 100,
  "model_type": "claude",
  "model_name": "claude-3-5-sonnet-20241022",
  "api_key": "sk-ant-api03-your-key",
  "api_base_url": "https://api.anthropic.com",
  "additional_params": {
    "temperature": 0,
    "max_tokens": 4096,
    "top_p": 1.0
  }
}
```

### é€šä¹‰åƒé—®é…ç½®ï¼ˆå¯¹æ¯”ï¼‰

```json
{
  "model_id": 99,
  "model_type": "openai",
  "model_name": "qwen-max",
  "api_key": "your-dashscope-key",
  "api_base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1",
  "additional_params": {
    "temperature": 0,
    "max_tokens": 4096
  }
}
```

---

## ğŸ› å¸¸è§é—®é¢˜å’Œè§£å†³

### é—®é¢˜ 1ï¼šLangChain Anthropic å¯¼å…¥å¤±è´¥

**é”™è¯¯ä¿¡æ¯**ï¼š
```
ModuleNotFoundError: No module named 'langchain_anthropic'
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
pip install langchain-anthropic
```

---

### é—®é¢˜ 2ï¼šClaude API Key æ— æ•ˆ

**é”™è¯¯ä¿¡æ¯**ï¼š
```
Error: Invalid API Key
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. æ£€æŸ¥ API Key æ˜¯å¦æ­£ç¡®
2. æ£€æŸ¥ API Key æ˜¯å¦æœ‰æƒé™è®¿é—® Claude 3.5 Sonnet
3. ç™»å½• Anthropic æ§åˆ¶å°ç¡®è®¤

---

### é—®é¢˜ 3ï¼šæ¨¡å‹ç±»å‹è¯†åˆ«é”™è¯¯

**é”™è¯¯ä¿¡æ¯**ï¼š
```
ValueError: Unsupported LLM type: claude
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. æ£€æŸ¥ `LLMFactory._llm_types` æ˜¯å¦åŒ…å« "claude"
2. æ£€æŸ¥ `type_name` å­—æ®µæ˜¯å¦ä¸º "claude"
3. é‡å¯ SQLBot åç«¯

---

### é—®é¢˜ 4ï¼šSQL ç”Ÿæˆä¸å‡†ç¡®

**å¯èƒ½åŸå› **ï¼š
1. æ¸©åº¦å‚æ•°å¤ªé«˜ï¼ˆå»ºè®® 0ï¼‰
2. Prompt ç¼ºå°‘ä¸Šä¸‹æ–‡ï¼ˆæ£€æŸ¥æœ¯è¯­åº“ã€SQL ç¤ºä¾‹ï¼‰
3. RAG æ£€ç´¢ä¸å‡†ç¡®ï¼ˆæ£€æŸ¥å‘é‡å­˜å‚¨ï¼‰

**è§£å†³æ–¹æ¡ˆ**ï¼š
```sql
-- 1. é™ä½æ¸©åº¦
UPDATE ai_model_detail 
SET temperature = 0 
WHERE base_model = 'claude-3-5-sonnet-20241022';

-- 2. æ£€æŸ¥æœ¯è¯­åº“
SELECT * FROM terminology LIMIT 10;

-- 3. æ£€æŸ¥ SQL ç¤ºä¾‹
SELECT * FROM data_training LIMIT 10;

-- 4. æ£€æŸ¥ Prompt é…ç½®
SELECT * FROM custom_prompt WHERE enabled = true;
```

---

## ğŸ“ å›é€€æ–¹æ¡ˆ

å¦‚æœ Claude ä¸æ»¡è¶³éœ€æ±‚ï¼Œå¯ä»¥å¿«é€Ÿåˆ‡æ¢å›é€šä¹‰åƒé—®ï¼š

```sql
-- åˆ‡æ¢å›é€šä¹‰åƒé—®
UPDATE ai_model_detail 
SET default_model = true 
WHERE base_model LIKE 'qwen%';
```

æˆ–è€…é€šè¿‡å‰ç«¯ï¼š
1. ç³»ç»Ÿè®¾ç½® â†’ AI æ¨¡å‹ç®¡ç†
2. é€‰æ‹©é€šä¹‰åƒé—®
3. ç‚¹å‡»"è®¾ä¸ºé»˜è®¤"

---

## ğŸ“‹ æ£€æŸ¥æ¸…å•

### å®æ–½å‰æ£€æŸ¥

- [ ] å·²å®‰è£… `langchain-anthropic`
- [ ] å·²è·å– Claude API Key
- [ ] å·²å¤‡ä»½ SQLBot æ•°æ®åº“
- [ ] å·²é˜…è¯» SQLBot æ–‡æ¡£

### å®æ–½åæ£€æŸ¥

- [ ] Claude LLM ç±»å·²åˆ›å»º
- [ ] LLMFactory å·²æ³¨å†Œ Claude
- [ ] get_default_config å·²ä¿®æ”¹
- [ ] Claude æ¨¡å‹å·²æ·»åŠ åˆ°æ•°æ®åº“
- [ ] Claude å·²è®¾ç½®ä¸ºé»˜è®¤æ¨¡å‹
- [ ] SQLBot åç«¯å¯åŠ¨æˆåŠŸ
- [ ] å‰ç«¯å¯ä»¥æ­£å¸¸è®¿é—®
- [ ] æµ‹è¯•æŸ¥è¯¢æ­£å¸¸
- [ ] æ—¥å¿—æ˜¾ç¤ºä½¿ç”¨çš„æ˜¯ Claude

---

## ğŸš€ å®Œæ•´ä»£ç ç¤ºä¾‹

### æ–‡ä»¶ï¼šapps/ai_model/llm.pyï¼ˆå®Œæ•´ä¿®æ”¹ï¼‰

```python
from functools import lru_cache
import json
from abc import ABC, abstractmethod
from typing import Optional, Dict, Any, Type

from langchain.chat_models.base import BaseChatModel
from pydantic import BaseModel
from sqlmodel import Session, select

# æ–°å¢å¯¼å…¥
from langchain_anthropic import ChatAnthropic

from apps.ai_model.openai.llm import BaseChatOpenAI
from apps.system.models.system_model import AiModelDetail
from common.core.db import engine
from common.utils.crypto import sqlbot_decrypt
from common.utils.utils import prepare_model_arg
from langchain_community.llms import VLLMOpenAI
from langchain_openai import AzureChatOpenAI

class LLMConfig(BaseModel):
    """Base configuration class for large language models"""
    model_id: Optional[int] = None
    model_type: str  # Model type: openai/tongyi/vllm/claude etc.
    model_name: str  # Specific model name
    api_key: Optional[str] = None
    api_base_url: Optional[str] = None
    additional_params: Dict[str, Any] = {}
    class Config:
        frozen = True

    def __hash__(self):
        if hasattr(self, 'additional_params') and isinstance(self.additional_params, dict):
            hashable_params = frozenset((k, tuple(v) if isinstance(v, (list, dict)) else v) 
                            for k, v in self.additional_params.items())
        else:
            hashable_params = None
        
        return hash((
            self.model_id,
            self.model_type,
            self.model_name,
            self.api_key,
            self.api_base_url,
            hashable_params
        ))

class BaseLLM(ABC):
    """Abstract base class for large language models"""

    def __init__(self, config: LLMConfig):
        self.config = config
        self._llm = self._init_llm()

    @abstractmethod
    def _init_llm(self) -> BaseChatModel:
        """Initialize specific large language model instance"""
        pass

    @property
    def llm(self) -> BaseChatModel:
        """Return the langchain LLM instance"""
        return self._llm

class OpenAIvLLM(BaseLLM):
    def _init_llm(self) -> VLLMOpenAI:
        return VLLMOpenAI(
            openai_api_key=self.config.api_key or 'Empty',
            openai_api_base=self.config.api_base_url,
            model_name=self.config.model_name,
            streaming=True,
            **self.config.additional_params,
        )

class OpenAIAzureLLM(BaseLLM):
    def _init_llm(self) -> AzureChatOpenAI:
        api_version = self.config.additional_params.get("api_version")
        deployment_name = self.config.additional_params.get("deployment_name")
        if api_version:
            self.config.additional_params.pop("api_version")
        if deployment_name:
            self.config.additional_params.pop("deployment_name")
        return AzureChatOpenAI(
            azure_endpoint=self.config.api_base_url,
            api_key=self.config.api_key or 'Empty',
            model_name=self.config.model_name,
            api_version=api_version,
            deployment_name=deployment_name,
            streaming=True,
            **self.config.additional_params,
        )
    
class OpenAILLM(BaseLLM):
    def _init_llm(self) -> BaseChatModel:
        return BaseChatOpenAI(
            model=self.config.model_name,
            api_key=self.config.api_key or 'Empty',
            base_url=self.config.api_base_url,
            stream_usage=True,
            **self.config.additional_params,
        )

    def generate(self, prompt: str) -> str:
        return self.llm.invoke(prompt)

# æ–°å¢ï¼šClaude LLM
class ClaudeLLM(BaseLLM):
    """
    Claude LLM å®ç°
    åŸºäº Anthropic Claude 3.5 Sonnet
    """
    
    def _init_llm(self) -> BaseChatModel:
        """
        åˆå§‹åŒ– Claude LLM å®ä¾‹
        
        Returns:
            ChatAnthropic: LangChain Claude å®ä¾‹
        """
        return ChatAnthropic(
            model=self.config.model_name,
            api_key=self.config.api_key or 'Empty',
            base_url=self.config.api_base_url,
            temperature=self.config.additional_params.get('temperature', 0),
            max_tokens=self.config.additional_params.get('max_tokens', 4096),
            streaming=True,
            **{k: v for k, v in self.config.additional_params.items() 
               if k not in ['temperature', 'max_tokens']}
        )

class LLMFactory:
    """Large Language Model Factory Class"""

    _llm_types: Dict[str, Type[BaseLLM]] = {
        "openai": OpenAILLM,
        "tongyi": OpenAILLM,
        "vllm": OpenAIvLLM,
        "azure": OpenAIAzureLLM,
        "claude": ClaudeLLM,  # æ–°å¢
    }

    @classmethod
    @lru_cache(maxsize=32)
    def create_llm(cls, config: LLMConfig) -> BaseLLM:
        llm_class = cls._llm_types.get(config.model_type)
        if not llm_class:
            raise ValueError(f"Unsupported LLM type: {config.model_type}")
        return llm_class(config)

    @classmethod
    def register_llm(cls, model_type: str, llm_class: Type[BaseLLM]):
        """Register new model type"""
        cls._llm_types[model_type] = llm_class

async def get_default_config() -> LLMConfig:
    """
    è·å–é»˜è®¤ LLM é…ç½®
    æ”¯æŒ Claude æ¨¡å‹
    """
    with Session(engine) as session:
        db_model = session.exec(
            select(AiModelDetail).where(AiModelDetail.default_model == True)
        ).first()
        if not db_model:
            raise Exception("The system default model has not been set")

        additional_params = {}
        if db_model.config:
            try:
                config_raw = json.loads(db_model.config)
                additional_params = {
                    item["key"]: prepare_model_arg(item.get('val'))
                    for item in config_raw
                    if "key" in item and "val" in item
                }
            except Exception:
                pass
        
        if not db_model.api_domain.startswith("http"):
            db_model.api_domain = await sqlbot_decrypt(db_model.api_domain)
            if db_model.api_key:
                db_model.api_key = await sqlbot_decrypt(db_model.api_key)
        
        # ç¡®å®š model_typeï¼ˆæ”¯æŒ Claudeï¼‰
        if "claude" in db_model.base_model.lower():
            model_type = "claude"
        elif db_model.protocol == 1:
            model_type = "openai"
        elif db_model.protocol == 2:
            model_type = "vllm"
        else:
            model_type = "openai"
        
        return LLMConfig(
            model_id=db_model.id,
            model_type=model_type,
            model_name=db_model.base_model,
            api_key=db_model.api_key,
            api_base_url=db_model.api_domain,
            additional_params=additional_params,
        )
```

---

## ğŸ“ æ€»ç»“

### æ–¹æ¡ˆB æ ¸å¿ƒä¼˜åŠ¿

1. âœ… **ä¿ç•™ SQLBot çš„ RAG**ï¼šSchemaã€æœ¯è¯­åº“ã€SQL ç¤ºä¾‹
2. âœ… **æœ€å°åŒ–ä»£ç æ”¹åŠ¨**ï¼šåªéœ€ä¿®æ”¹ 3 ä¸ªåœ°æ–¹
3. âœ… **é£é™©æœ€ä½**ï¼šä¿ç•™ SQLBot çš„æ‰€æœ‰ä¼˜åŒ–ç»éªŒ
4. âœ… **å·¥ä½œé‡æœ€å°**ï¼š2.5-4.5 å¤©å®Œæˆ
5. âœ… **å¯å¿«é€Ÿåˆ‡æ¢**ï¼šéšæ—¶å¯ä»¥åˆ‡æ¢å›é€šä¹‰åƒé—®

### å®æ–½æ—¶é—´è¡¨

| é˜¶æ®µ | ä»»åŠ¡ | æ—¶é—´ |
|------|------|------|
| **é˜¶æ®µ 1** | å®‰è£…ä¾èµ– | 10 åˆ†é’Ÿ |
| **é˜¶æ®µ 2** | åˆ›å»º Claude LLM ç±» | 30 åˆ†é’Ÿ |
| **é˜¶æ®µ 3** | æ³¨å†Œ Claude LLM | 20 åˆ†é’Ÿ |
| **é˜¶æ®µ 4** | ä¿®æ”¹ get_default_config() | 30 åˆ†é’Ÿ |
| **é˜¶æ®µ 5** | æ·»åŠ  Claude æ¨¡å‹é…ç½® | 10 åˆ†é’Ÿ |
| **é˜¶æ®µ 6** | éªŒè¯é…ç½® | 10 åˆ†é’Ÿ |
| **é˜¶æ®µ 7** | æµ‹è¯•å’Œè°ƒä¼˜ | 1-2 å°æ—¶ |
| **æ€»è®¡** | | **2.5-4.5 å°æ—¶** |

### ä¸‹ä¸€æ­¥

**å®æ–½å»ºè®®**ï¼š
1. å…ˆåœ¨æµ‹è¯•ç¯å¢ƒå®Œæˆæ­¥éª¤ 1-6
2. éªŒè¯åŸºæœ¬åŠŸèƒ½æ­£å¸¸
3. è¿›è¡Œé˜¶æ®µ 7 çš„è¯¦ç»†æµ‹è¯•
4. éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ

**ä½ çš„é€‰æ‹©**ï¼š
1. ç°åœ¨å¼€å§‹å®æ–½ï¼Ÿ
2. è¿˜æœ‰ç–‘é—®éœ€è¦è§£ç­”ï¼Ÿ

---

*æ–‡æ¡£ç”Ÿæˆæ—¶é—´ï¼š2026-02-08*
*æœ€åæ›´æ–°ï¼š2026-02-08*
